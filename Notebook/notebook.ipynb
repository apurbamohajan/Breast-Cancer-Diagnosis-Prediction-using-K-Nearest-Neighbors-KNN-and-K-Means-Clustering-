{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95f0504",
   "metadata": {},
   "source": [
    "Breast Cancer Diagnosis Prediction using K-Nearest Neighbors (KNN) and K-Means Clustering \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a7da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure matplotlib is installed in this environment\n",
    "import sys, subprocess\n",
    "try:\n",
    "    import matplotlib\n",
    "except ModuleNotFoundError:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\", \"-q\"])\n",
    "    import matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset at: ..\\Dataset\\Dataset.csv\n",
      "Loaded dataset shape: (569, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (455, 30) Test shape: (114, 30)\n",
      "\n",
      "Contingency table (cluster vs diagnosis):\n",
      "diagnosis    0    1\n",
      "cluster            \n",
      "0            9  180\n",
      "1          348   32\n",
      "Cluster -> majority label mapping: {np.int32(0): 1, np.int32(1): 0}\n",
      "Clustering accuracy (after mapping clusters to labels): 0.9279\n",
      "\n",
      "KNN (k=5) Evaluation on test set:\n",
      "Accuracy: 0.9649\n",
      "Precision: 1.0000\n",
      "Recall: 0.9048\n",
      "F1-score: 0.9500\n",
      "\n",
      "Confusion Matrix (rows=true, cols=predicted):\n",
      "            Pred 0 (B)  Pred 1 (M)\n",
      "True 0 (B)          72           0\n",
      "True 1 (M)           4          38\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Benign (0)       0.95      1.00      0.97        72\n",
      "Malignant (1)       1.00      0.90      0.95        42\n",
      "\n",
      "     accuracy                           0.96       114\n",
      "    macro avg       0.97      0.95      0.96       114\n",
      " weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "\\nSaved outputs to folder: breast_cancer_assignment_output\n",
      "Zipped package: breast_cancer_assignment_submission.zip\n"
     ]
    }
   ],
   "source": [
    "# Ready-to-run pipeline for:\n",
    "# \"Breast Cancer Diagnosis Prediction using KNN and K-Means\"\n",
    "# Put Dataset.csv into the same folder or upload to Colab.\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except ModuleNotFoundError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib\", \"-q\"])\n",
    "    import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import nbformat as nbf\n",
    "except ModuleNotFoundError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nbformat\", \"-q\"])\n",
    "    import nbformat as nbf\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "# Default (project-relative) path. Update if you run the notebook from a different folder.\n",
    "DEFAULT_DATA_PATHS = [\n",
    "    \"Dataset.csv\",                       # same folder as notebook/process\n",
    "    os.path.join(\"..\", \"Dataset\", \"Dataset.csv\"),  # when running from Notebook/ folder\n",
    "    os.path.join(\"..\", \"..\", \"Dataset\", \"Dataset.csv\"),\n",
    "    os.path.join(\"Dataset\", \"Dataset.csv\"),\n",
    "]\n",
    "\n",
    "OUT_DIR = \"breast_cancer_assignment_output\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- 1. Load ----------\n",
    "# Resolve DATA_PATH by checking common locations\n",
    "DATA_PATH = None\n",
    "for p in DEFAULT_DATA_PATHS:\n",
    "    if os.path.exists(p):\n",
    "        DATA_PATH = p\n",
    "        break\n",
    "\n",
    "# If not found yet, allow absolute path environment override\n",
    "if DATA_PATH is None:\n",
    "    env_path = os.environ.get(\"DATA_PATH\")\n",
    "    if env_path and os.path.exists(env_path):\n",
    "        DATA_PATH = env_path\n",
    "\n",
    "if DATA_PATH is None:\n",
    "    tried = [os.path.abspath(p) for p in DEFAULT_DATA_PATHS]\n",
    "    raise FileNotFoundError(\n",
    "        \"Dataset.csv not found. Tried the following paths:\\n\" + \"\\n\".join(tried) +\n",
    "        \"\\n\\nPlace Dataset.csv in one of those locations or set the DATA_PATH variable to the absolute file path.\\nExample: DATA_PATH = 'C:/full/path/to/Dataset/Dataset.csv'\"\n",
    "    )\n",
    "\n",
    "print(f\"Using dataset at: {DATA_PATH}\")\n",
    "\n",
    "# Defensive: if pd.read_csv was accidentally overwritten in the kernel, reload pandas and retry\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "except TypeError:\n",
    "    import importlib\n",
    "    importlib.reload(pd)\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Loaded dataset shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# ---------- 2. Preprocess ----------\n",
    "# Encode diagnosis: M -> 1, B -> 0\n",
    "if 'diagnosis' not in df.columns:\n",
    "    raise ValueError(\"Column 'diagnosis' not found. Check dataset.\")\n",
    "df['diagnosis'] = df['diagnosis'].map({'M':1, 'B':0})\n",
    "\n",
    "# Drop 'id' and 'Unnamed: 32' if present\n",
    "for col in ['id', 'Unnamed: 32', 'Unnamed:32']:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "# Separate features & target\n",
    "y = df['diagnosis']\n",
    "X = df.drop(columns=['diagnosis'])\n",
    "\n",
    "# ---------- 3. Min-Max Normalization ----------\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# ---------- 4. Train/Test Split (80/20) ----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "\n",
    "# ---------- 5. KMeans clustering (k=2) ----------\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "kmeans.fit(X_scaled)\n",
    "clusters = kmeans.labels_\n",
    "\n",
    "# Compare cluster assignments to true labels\n",
    "cluster_df = pd.DataFrame({'diagnosis': y.values, 'cluster': clusters})\n",
    "contingency = pd.crosstab(cluster_df['cluster'], cluster_df['diagnosis'])\n",
    "print(\"\\nContingency table (cluster vs diagnosis):\")\n",
    "print(contingency)\n",
    "\n",
    "# Map each cluster to the majority class inside it\n",
    "cluster_to_label = {}\n",
    "for cl in sorted(cluster_df['cluster'].unique()):\n",
    "    counts = cluster_df[cluster_df['cluster']==cl]['diagnosis'].value_counts()\n",
    "    cluster_to_label[cl] = int(counts.idxmax())\n",
    "print(\"Cluster -> majority label mapping:\", cluster_to_label)\n",
    "\n",
    "cluster_pred_label = np.array([cluster_to_label[c] for c in clusters])\n",
    "clustering_accuracy = (cluster_pred_label == y.values).mean()\n",
    "print(f\"Clustering accuracy (after mapping clusters to labels): {clustering_accuracy:.4f}\")\n",
    "\n",
    "# ---------- 6. KNN classifier (k=5) ----------\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# ---------- 7. Evaluation ----------\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"\\nKNN (k=5) Evaluation on test set:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=predicted):\")\n",
    "print(pd.DataFrame(cm, index=['True 0 (B)','True 1 (M)'], columns=['Pred 0 (B)','Pred 1 (M)']))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Benign (0)','Malignant (1)']))\n",
    "\n",
    "# ---------- 8. Save outputs ----------\n",
    "# Confusion matrix figure\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.xticks([0,1], ['Benign (0)','Malignant (1)'])\n",
    "plt.yticks([0,1], ['Benign (0)','Malignant (1)'])\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, cm[i,j], ha='center', va='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Save preview CSV of test predictions\n",
    "test_results = X_test.copy()\n",
    "test_results['true'] = y_test.values\n",
    "test_results['pred'] = y_pred\n",
    "test_results.head(20).to_csv(os.path.join(OUT_DIR, \"test_predictions_preview.csv\"), index=False)\n",
    "\n",
    "# Create a simple notebook file with the same pipeline so you can open in Colab\n",
    "notebook_code = \"\"\"# Breast Cancer Diagnosis - KNN & KMeans\n",
    "\n",
    "# (The notebook code is the same pipeline as the script. Upload Dataset.csv to the notebook path and run.)\n",
    "\"\"\"\n",
    "nb = nbf.v4.new_notebook()\n",
    "nb['cells'] = [\n",
    "    nbf.v4.new_markdown_cell(\"# Breast Cancer Diagnosis Prediction\\nThis notebook reproduces the preprocessing, KMeans clustering and KNN classifier evaluation.\"),\n",
    "    nbf.v4.new_code_cell(\"# Paste the same pipeline code here if you want to run it step by step in Colab.\")\n",
    "]\n",
    "nb_path = os.path.join(OUT_DIR, \"breast_cancer_knn_kmeans.ipynb\")\n",
    "with open(nb_path, 'w') as f:\n",
    "    nbf.write(nb, f)\n",
    "\n",
    "# README\n",
    "readme_text = \"\"\"# Breast Cancer Diagnosis (KNN & KMeans)\n",
    "\n",
    "Steps & files included:\n",
    "- Dataset.csv (upload to Colab / local folder)\n",
    "- This notebook: breast_cancer_knn_kmeans.ipynb\n",
    "- confusion_matrix.png\n",
    "- test_predictions_preview.csv\n",
    "\n",
    "How to run:\n",
    "1. Open the notebook or run this script.\n",
    "2. Ensure Dataset.csv is available in the working directory.\n",
    "3. Run all cells or execute the script.\n",
    "\"\"\"\n",
    "with open(os.path.join(OUT_DIR, \"README.md\"), 'w') as f:\n",
    "    f.write(readme_text)\n",
    "\n",
    "# Zip up outputs\n",
    "zip_path = \"breast_cancer_assignment_submission.zip\"\n",
    "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as z:\n",
    "    for root, _, files in os.walk(OUT_DIR):\n",
    "        for file in files:\n",
    "            z.write(os.path.join(root, file), arcname=file)\n",
    "\n",
    "print(\"\\\\nSaved outputs to folder:\", OUT_DIR)\n",
    "print(\"Zipped package:\", zip_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
